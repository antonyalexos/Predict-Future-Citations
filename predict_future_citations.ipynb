{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T19:59:36.857987Z",
     "start_time": "2019-01-31T19:59:33.526771Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "from statistics import mode\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import keras\n",
    "from keras.initializers import Constant\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Conv1D,LSTM,MaxPooling1D,Flatten,SimpleRNN,SpatialDropout3D\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T20:01:14.993912Z",
     "start_time": "2019-01-31T20:01:12.963231Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('outputacm.txt',\"r\",errors='ignore') as f:\n",
    "        lines= f.readlines()\n",
    "\n",
    "def get_data(lines):        \n",
    "    year_ids = []\n",
    "    index_ids=[]\n",
    "    cited_ids=[]\n",
    "\n",
    "    for line in lines:\n",
    "        if line[0:2]==\"#t\":\n",
    "            year_ids.append(int(re.search(r'\\d+', line).group()))\n",
    "        elif line[0:2]==\"#i\":\n",
    "            index_ids.append(int(re.search(r'\\d+', line).group()))\n",
    "        elif line[0:2]==\"#%\":\n",
    "            cited_ids.append(int(re.search(r'\\d+', line).group()))\n",
    "\n",
    "    for i,j in zip(range(len(index_ids)),range(len(cited_ids))):\n",
    "        index_ids[i]=int(index_ids[i])\n",
    "        year_ids[i]=int(year_ids[i])\n",
    "        cited_ids[j]=int(cited_ids[j])\n",
    "\n",
    "    citations=np.zeros(len(year_ids))\n",
    "\n",
    "    for i in cited_ids:\n",
    "        #i=int(i)\n",
    "        citations[i]=citations[i]+1\n",
    "\n",
    "    data=pd.DataFrame({'Index':index_ids,'Citations':citations})\n",
    "    data=data[data['Citations']>10]\n",
    "    return data\n",
    "\n",
    "def get_top10(group):\n",
    "    return group.sort_values(by='Citations', ascending=False)[:10]\n",
    "\n",
    "def group_function():\n",
    "    year2=[]\n",
    "    cited2=[]\n",
    "    flag=0\n",
    "    for line in lines:\n",
    "\n",
    "        if line[0:2]==\"#t\":\n",
    "            flag=1\n",
    "            year2.append(line[2:-1])\n",
    "        elif line[0:2]==\"#%\":\n",
    "            cited2.append(int(re.search(r'\\d+', line).group()))\n",
    "            if(flag==2):\n",
    "                year2.append(year2[len(year2)-1])\n",
    "            flag=2\n",
    "        elif line[0:2]==\"#*\":\n",
    "            if(flag==1):\n",
    "                year2.pop()\n",
    "            flag=0\n",
    "    year2.pop();\n",
    "    for i in range(len(year2)):\n",
    "        year2[i]=int(year2[i])\n",
    "        cited2[i]=int(cited2[i])\n",
    "\n",
    "    df=pd.DataFrame({'Year':year2,'Index':cited2})\n",
    "    df=df.sort_values(['Index','Year'])\n",
    "    df=df.reset_index()\n",
    "    df.drop(['index'],axis=1,inplace=True)\n",
    "\n",
    "    df=df.groupby(['Year','Index']).size().reset_index(name='Count')\n",
    "    df=df.sort_values(['Index','Year'])\n",
    "    df=df.reset_index()\n",
    "    df.drop(['index'],axis=1,inplace=True)\n",
    "    return df\n",
    "    \n",
    "def get_unique(df):\n",
    "    df=df[(df['Index'].isin(data['Index']))]\n",
    "    df=df.reset_index()\n",
    "    df.drop(['index'],axis=1,inplace=True)\n",
    "    unique_indexes=df['Index'].unique()\n",
    "    return unique_indexes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T20:01:29.103161Z",
     "start_time": "2019-01-31T20:01:23.734809Z"
    }
   },
   "outputs": [],
   "source": [
    "data=get_data(lines)\n",
    "data=get_top10(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T20:01:39.281187Z",
     "start_time": "2019-01-31T20:01:35.280978Z"
    }
   },
   "outputs": [],
   "source": [
    "df = group_function()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T20:01:46.432563Z",
     "start_time": "2019-01-31T20:01:46.409427Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 79620,  81323, 151297, 162585, 214951, 311413, 319217, 326368,\n",
       "       453387, 586607])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_indexes = get_unique(df)\n",
    "unique_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T20:02:37.426021Z",
     "start_time": "2019-01-31T20:02:36.076900Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got train datasets with length 42 , 40 , 29 , 25 , 17 , 21 , 31 , 40 , 19 , 13\n"
     ]
    }
   ],
   "source": [
    "#https://docs.python.org/3/tutorial/classes.html\n",
    "class MyClass:\n",
    "    pass\n",
    "\n",
    "p1 = MyClass()\n",
    "p1.year=[]\n",
    "p1.counted=[]\n",
    "p2 = MyClass()\n",
    "p2.year=[]\n",
    "p2.counted=[]\n",
    "p3 = MyClass()\n",
    "p3.year=[]\n",
    "p3.counted=[]\n",
    "p4 = MyClass()\n",
    "p4.year=[]\n",
    "p4.counted=[]\n",
    "p5 = MyClass()\n",
    "p5.year=[]\n",
    "p5.counted=[]\n",
    "p6 = MyClass()\n",
    "p6.year=[]\n",
    "p6.counted=[]\n",
    "p7 = MyClass()\n",
    "p7.year=[]\n",
    "p7.counted=[]\n",
    "p8 = MyClass()\n",
    "p8.year=[]\n",
    "p8.counted=[]\n",
    "p9 = MyClass()\n",
    "p9.year=[]\n",
    "p9.counted=[]\n",
    "p10 = MyClass()\n",
    "p10.year=[]\n",
    "p10.counted=[]\n",
    "\n",
    "for i,j,k in zip(df['Index'],df['Year'],df['Count']):\n",
    "    if(i==unique_indexes[0]):\n",
    "        p1.year.append(j)\n",
    "        p1.counted.append(k)\n",
    "    elif(i==unique_indexes[1]):\n",
    "        p2.year.append(j)\n",
    "        p2.counted.append(k)\n",
    "    elif(i==unique_indexes[2]):\n",
    "        p3.year.append(j)\n",
    "        p3.counted.append(k)\n",
    "    elif(i==unique_indexes[3]):\n",
    "        p4.year.append(j)\n",
    "        p4.counted.append(k)\n",
    "    elif(i==unique_indexes[4]):\n",
    "        p5.year.append(j)\n",
    "        p5.counted.append(k)\n",
    "    elif(i==unique_indexes[5]):\n",
    "        p6.year.append(j)\n",
    "        p6.counted.append(k)\n",
    "    elif(i==unique_indexes[6]):\n",
    "        p7.year.append(j)\n",
    "        p7.counted.append(k)\n",
    "    elif(i==unique_indexes[7]):\n",
    "        p8.year.append(j)\n",
    "        p8.counted.append(k)\n",
    "    elif(i==unique_indexes[8]):\n",
    "        p9.year.append(j)\n",
    "        p9.counted.append(k)\n",
    "    elif(i==unique_indexes[9]):\n",
    "        p10.year.append(j)\n",
    "        p10.counted.append(k)\n",
    "\n",
    "train_data1 = pd.DataFrame({'Year':p1.year,'Citations':p1.counted})\n",
    "train_data2 = pd.DataFrame({'Year':p2.year,'Citations':p2.counted})\n",
    "train_data3 = pd.DataFrame({'Year':p3.year,'Citations':p3.counted})\n",
    "train_data4 = pd.DataFrame({'Year':p4.year,'Citations':p4.counted})\n",
    "train_data4 = train_data4.drop(train_data4.index[-1])\n",
    "train_data5 = pd.DataFrame({'Year':p5.year,'Citations':p5.counted})\n",
    "train_data6 = pd.DataFrame({'Year':p6.year,'Citations':p6.counted})\n",
    "train_data7 = pd.DataFrame({'Year':p7.year,'Citations':p7.counted})\n",
    "train_data8 = pd.DataFrame({'Year':p8.year,'Citations':p8.counted})\n",
    "train_data9 = pd.DataFrame({'Year':p9.year,'Citations':p9.counted})\n",
    "train_data10 = pd.DataFrame({'Year':p10.year,'Citations':p10.counted})\n",
    "\n",
    "print(\"We got train datasets with length\",len(train_data1),\",\",len(train_data2),\",\",len(train_data3),\",\",len(train_data4),\",\",len(train_data5),\",\",len(train_data6),\",\",len(train_data7),\",\",len(train_data8),\",\",len(train_data9),\",\",len(train_data10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T20:39:29.961863Z",
     "start_time": "2019-01-31T20:39:18.773666Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 4 7 5 4\n",
      "Training time:  11.176334142684937\n"
     ]
    }
   ],
   "source": [
    "train1=np.array(train_data1)\n",
    "train2=np.array(train_data2)\n",
    "train3=np.array(train_data3)\n",
    "train4=np.array(train_data4)\n",
    "train5=np.array(train_data5)\n",
    "train6=np.array(train_data6)\n",
    "train7=np.array(train_data7)\n",
    "train8=np.array(train_data8)\n",
    "train9=np.array(train_data9)\n",
    "train10=np.array(train_data10)\n",
    "\n",
    "timestart=time.time()   #time start of the training\n",
    "\n",
    "\n",
    "train=train8\n",
    "\n",
    "x_train = train[0:len(train)-5,1]\n",
    "\n",
    "x_test = train[(len(train)-5):,1]\n",
    "\n",
    "x_test=np.array(x_test)\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "# #we read the data from the professor's texts\n",
    "# cit_num=pd.read_csv('timeseries01.txt',delimiter=';',header=None).T\n",
    "# year_num=pd.read_csv('timeseries01-year.txt',delimiter=';',header=None).T\n",
    "# df2.columns.names=['Year']\n",
    "# df1.columns.names=['No of citations']\n",
    "# timeseries=np.hstack((year_num,cit_num))\n",
    "#timestart=time.time()   #time start of the training\n",
    "# train=timeseries\n",
    "\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif out_end_ix > len(sequence):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = (len(x_train)-5), 5\n",
    "# split into samples\n",
    "X, y = split_sequence(x_train, n_steps_in, n_steps_out)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=256, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X, y, epochs=2000, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = x_train[-n_steps_in:]\n",
    "x_input = np.array(x_input)\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "prediction = model.predict(x_input, verbose=0)\n",
    "print(math.ceil(prediction[0][0]),math.ceil(prediction[0][1]),math.ceil(prediction[0][2]),math.ceil(prediction[0][3]),math.ceil(prediction[0][4]))\n",
    "\n",
    "time_end=time.time()\n",
    "\n",
    "time_needed=time_end-timestart\n",
    "print(\"Training time: \",time_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T20:06:41.211601Z",
     "start_time": "2019-01-31T20:06:41.206490Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  8  4 16 24 31 15 28 17 15 20 32 19 32 15 20 28 26 22 14 21 11 16\n",
      "  9 23  7  6  1  3  8  5  7  6  4]\n",
      "[10  9  5 17  9]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T21:23:39.025185Z",
     "start_time": "2019-01-30T21:23:39.015226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_80 (Conv1D)           (None, 35, 256)           768       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 17, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_80 (Flatten)         (None, 4352)              0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 50)                217650    \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 218,520\n",
      "Trainable params: 218,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T21:23:53.853491Z",
     "start_time": "2019-01-30T21:23:53.603209Z"
    }
   },
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
